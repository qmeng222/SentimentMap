{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d272b626",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Reddit Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb8a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai.error import APIConnectionError, APIError, RateLimitError\n",
    "from typing import List, Dict, Generator, Optional\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import praw\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045ff555",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "load_dotenv(\".env\")\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.environ[\"REDDIT_CLIENT_ID\"],\n",
    "    client_secret=os.environ[\"REDDIT_CLIENT_SECRET\"],\n",
    "    user_agent=f\"script:test:0.0.1 (by u/yourusername)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ebfa977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "\n",
    "def num_tokens_from_messages(messages, model):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model == \"gpt-3.5-turbo\":\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\")\n",
    "    elif model == \"gpt-4\":\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0314\")\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif model == \"gpt-4-0314\":\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe29f1",
   "metadata": {},
   "source": [
    "## Getting Reddit Comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b5413ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_COLUMNS = [\"subreddit\", \"submission_id\", \"score\", \"comment_body\"]\n",
    "# filename, subreddits = \"cities.csv\", [\n",
    "#     \"NYC\",\n",
    "#     \"Seattle\",\n",
    "#     \"LosAngeles\",\n",
    "#     \"Chicago\",\n",
    "#     \"Austin\",\n",
    "#     \"Portland\",\n",
    "#     \"SanFrancisco\",\n",
    "#     \"Boston\",\n",
    "#     \"Houston\",\n",
    "#     \"Atlanta\",\n",
    "#     \"Philadelphia\",\n",
    "#     \"Denver\",\n",
    "#     \"SeattleWa\",\n",
    "#     \"Dallas\",\n",
    "#     \"WashingtonDC\",\n",
    "#     \"SanDiego\",\n",
    "#     \"Pittsburgh\",\n",
    "#     \"Phoenix\",\n",
    "#     \"Minneapolis\",\n",
    "#     \"Orlando\",\n",
    "#     \"Nashville\",\n",
    "#     \"StLouis\",\n",
    "#     \"SaltLakeCity\",\n",
    "#     \"Columbus\",\n",
    "#     \"Raleigh\",\n",
    "# ]\n",
    "\n",
    "# OTHER POTENTIAL SUBREDDITS TO TRY:\n",
    "# filename, subreddits = \"iphone_v_android.csv\", [\"iphone\", \"Android\"]\n",
    "# filename, subreddits = \"startrek_v_starwars.csv\", [\"startrek\", \"StarWars\"]\n",
    "filename, subreddits = \"epl_top_8.csv\", [\"reddevils\", \"LiverpoolFC\", \"chelseafc\", \"Gunners\", \"coys\", \"MCFC\", \"Everton\", \"NUFC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed05f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for fetching comments from submissions\n",
    "def comment_generator(submission) -> Generator:\n",
    "    # Do not bother expanding MoreComments (follow-links)\n",
    "    for comment in submission.comments.list():\n",
    "        if hasattr(comment, \"body\") and comment.body != \"[deleted]\" and comment.body != \"[removed]\":\n",
    "            yield (comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716d6644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_comments(\n",
    "    filename: str,\n",
    "    target_comments_per_subreddit: int,\n",
    "    max_comments_per_submission: int,\n",
    "    max_comment_length: int,\n",
    "    reddit: praw.Reddit,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Collect comments from the top submissions in each subreddit.\n",
    "\n",
    "    Cache results at cache_filename.\n",
    "\n",
    "    Return a dataframe with columns: subreddit, submission_id, score, comment_body\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filename, index_col=\"id\")\n",
    "        assert df.columns.tolist() == DF_COLUMNS\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=DF_COLUMNS)\n",
    "\n",
    "    # dict like {comment_id -> {column -> value}}\n",
    "    records = df.to_dict(orient=\"index\")\n",
    "\n",
    "    for subreddit_index, subreddit_name in enumerate(subreddits):\n",
    "        print(f\"Processing Subreddit: {subreddit_name}\")\n",
    "\n",
    "        processed_comments_for_subreddit = len(df[df[\"subreddit\"] == subreddit_name])\n",
    "\n",
    "        if processed_comments_for_subreddit >= target_comments_per_subreddit:\n",
    "            print(f\"Enough comments fetched for {subreddit_name}, continuing to next subreddit.\")\n",
    "            continue\n",
    "\n",
    "        # `top`` is a generator, grab submissions until we break (within this loop).\n",
    "        for submission in reddit.subreddit(subreddit_name).top(time_filter=\"month\"):\n",
    "            if processed_comments_for_subreddit >= target_comments_per_subreddit:\n",
    "                break\n",
    "\n",
    "            # The number of comments that we already have for this subreddit\n",
    "            processed_comments_for_submission = len(df[df[\"submission_id\"] == submission.id])\n",
    "\n",
    "            for comment in comment_generator(submission):\n",
    "                if processed_comments_for_submission >= max_comments_per_submission or processed_comments_for_subreddit >= target_comments_per_subreddit:\n",
    "                    break\n",
    "\n",
    "                if comment.id in records:\n",
    "                    print(f\"Skipping comment {subreddit_name}-{submission.id}-{comment.id} because we already have it\")\n",
    "                    continue\n",
    "\n",
    "                body = comment.body[:max_comment_length].strip()\n",
    "                records[comment.id] = {\"subreddit\": subreddit_name, \"submission_id\": submission.id, \"comment_body\": body}\n",
    "\n",
    "                processed_comments_for_subreddit += 1\n",
    "                processed_comments_for_submission += 1\n",
    "\n",
    "            # Once per post write to disk.\n",
    "            print(f\"CSV rewritten with {len(records)} rows.\\n\")\n",
    "            df = pd.DataFrame.from_dict(records, orient=\"index\", columns=DF_COLUMNS)\n",
    "            df.to_csv(filename, index_label=\"id\")\n",
    "\n",
    "    print(\"Completed.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a2ddd",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a78d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ATTEMPTS = 3\n",
    "\n",
    "def generate_prompt_messages(s: str) -> List[Dict]:\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "The following is a comment from a user on Reddit. Score it from -1 to 1, where -1 is the most negative and 1 is the most positive:\n",
    "\n",
    "The traffic is quite annoying.\n",
    "\"\"\".strip(),\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": \"-0.75\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "The following is a comment from a user on Reddit. Score it from -1 to 1, where -1 is the most negative and 1 is the most positive:\n",
    "\n",
    "The library is downtown.\n",
    "\"\"\".strip(),\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": \"0.0\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "The following is a comment from a user on Reddit. Score it from -1 to 1, where -1 is the most negative and 1 is the most positive:\n",
    "\n",
    "Even though it's humid, I really love the summertime. Everything is so green and the sun is out all the time.\n",
    "\"\"\".strip(),\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": \"0.8\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "The following is a comment from a user on Reddit. Score it from -1 to 1, where -1 is the most negative and 1 is the most positive:\n",
    "\n",
    "{s}\n",
    "\"\"\".strip(),\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b812f",
   "metadata": {},
   "source": [
    "## Run Everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4664db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Subreddit: reddevils\n",
      "Enough comments fetched for reddevils, continuing to next subreddit.\n",
      "Processing Subreddit: LiverpoolFC\n",
      "Enough comments fetched for LiverpoolFC, continuing to next subreddit.\n",
      "Processing Subreddit: chelseafc\n",
      "Enough comments fetched for chelseafc, continuing to next subreddit.\n",
      "Processing Subreddit: Gunners\n",
      "Enough comments fetched for Gunners, continuing to next subreddit.\n",
      "Processing Subreddit: coys\n",
      "Enough comments fetched for coys, continuing to next subreddit.\n",
      "Processing Subreddit: MCFC\n",
      "Enough comments fetched for MCFC, continuing to next subreddit.\n",
      "Processing Subreddit: Everton\n",
      "Enough comments fetched for Everton, continuing to next subreddit.\n",
      "Processing Subreddit: NUFC\n",
      "Enough comments fetched for NUFC, continuing to next subreddit.\n",
      "Completed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>score</th>\n",
       "      <th>comment_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jkr0z7j</th>\n",
       "      <td>reddevils</td>\n",
       "      <td>13lqbis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Source: https://www.instagram.com/p/Csa1f8NM7-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jkr1710</th>\n",
       "      <td>reddevils</td>\n",
       "      <td>13lqbis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I always remember when he said no one would bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jkr0xqv</th>\n",
       "      <td>reddevils</td>\n",
       "      <td>13lqbis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poor guy with all the injuries - wishing him a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jkr1qh5</th>\n",
       "      <td>reddevils</td>\n",
       "      <td>13lqbis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"I've said before that I found it hard to even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jkr1v2g</th>\n",
       "      <td>reddevils</td>\n",
       "      <td>13lqbis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Even if injured, name him on the bench for fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jl7ubhu</th>\n",
       "      <td>NUFC</td>\n",
       "      <td>13p50iu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Someone make this our subreddit banner please\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jl7qp4f</th>\n",
       "      <td>NUFC</td>\n",
       "      <td>13p50iu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nick Pope absolutely makes this photo epic! LOL!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jl7q02h</th>\n",
       "      <td>NUFC</td>\n",
       "      <td>13p50iu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hands down best pic yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jl7puyp</th>\n",
       "      <td>NUFC</td>\n",
       "      <td>13p50iu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Murphy is saying it all for me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jl7q67n</th>\n",
       "      <td>NUFC</td>\n",
       "      <td>13p50iu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Murphy just has it. What a lad.. On another no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit submission_id  score  \\\n",
       "id                                        \n",
       "jkr0z7j  reddevils       13lqbis    NaN   \n",
       "jkr1710  reddevils       13lqbis    NaN   \n",
       "jkr0xqv  reddevils       13lqbis    NaN   \n",
       "jkr1qh5  reddevils       13lqbis    NaN   \n",
       "jkr1v2g  reddevils       13lqbis    NaN   \n",
       "...            ...           ...    ...   \n",
       "jl7ubhu       NUFC       13p50iu    NaN   \n",
       "jl7qp4f       NUFC       13p50iu    NaN   \n",
       "jl7q02h       NUFC       13p50iu    NaN   \n",
       "jl7puyp       NUFC       13p50iu    NaN   \n",
       "jl7q67n       NUFC       13p50iu    NaN   \n",
       "\n",
       "                                              comment_body  \n",
       "id                                                          \n",
       "jkr0z7j  Source: https://www.instagram.com/p/Csa1f8NM7-...  \n",
       "jkr1710  I always remember when he said no one would bo...  \n",
       "jkr0xqv  Poor guy with all the injuries - wishing him a...  \n",
       "jkr1qh5  \"I've said before that I found it hard to even...  \n",
       "jkr1v2g  Even if injured, name him on the bench for fin...  \n",
       "...                                                    ...  \n",
       "jl7ubhu  Someone make this our subreddit banner please\\...  \n",
       "jl7qp4f   Nick Pope absolutely makes this photo epic! LOL!  \n",
       "jl7q02h                            Hands down best pic yet  \n",
       "jl7puyp                     Murphy is saying it all for me  \n",
       "jl7q67n  Murphy just has it. What a lad.. On another no...  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_COMMENTS_PER_SUBREDDIT = 50\n",
    "MAX_COMMENTS_PER_SUBMISSION = 10\n",
    "MAX_COMMENT_LENGTH = 2000\n",
    "\n",
    "collect_comments(\n",
    "    filename=filename,\n",
    "    target_comments_per_subreddit=TARGET_COMMENTS_PER_SUBREDDIT,\n",
    "    max_comments_per_submission=MAX_COMMENTS_PER_SUBMISSION,\n",
    "    max_comment_length=MAX_COMMENT_LENGTH,\n",
    "    reddit=reddit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2709b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
